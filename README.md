# Algorithms-Data_Structures

<h1>Algorithms</h1>

1)Bubble Sort - Bubble sort is a simple sorting algorithm that works by repeatedly swapping adjacent elements if they are in the wrong order. It is called bubble sort because the smaller elements "bubble" to the top of the list, while the larger elements "sink" to the bottom. The algorithm proceeds by iterating through the list of elements, comparing each pair of adjacent elements, and swapping them if they are in the wrong order. This process is repeated until no more swaps are necessary, indicating that the list is sorted. Although bubble sort is simple to understand and implement, it has a worst-case time complexity of O(n^2), making it relatively inefficient for large lists. For this reason, it is usually only used for small lists or as an educational example of a sorting algorithm.

2)Insertion Sort - Insertion sort is a simple sorting algorithm that works by repeatedly taking an unsorted element and inserting it into the correct position in a sorted sub-list. It is particularly efficient for small data sets and nearly sorted lists. The algorithm proceeds by starting with a single element (the first element) and iterating through the list, comparing each subsequent element with the elements in the sorted sub-list and inserting it into the correct position. The sorted sub-list grows with each iteration until all elements have been inserted and the list is fully sorted. Insertion sort has an average and worst-case time complexity of O(n^2), making it relatively inefficient for large data sets. However, it has the advantage of being simple to understand and implement, and it performs well on small or nearly sorted lists. Additionally, insertion sort is often used as part of more complex sorting algorithms, such as merge sort or quicksort.

3)Merge Sort - Merge sort is a divide-and-conquer sorting algorithm that works by recursively dividing the input list into two halves, sorting each half, and then merging the sorted halves back together. It is a stable, comparison-based sorting algorithm with a worst-case time complexity of O(n log n). The algorithm proceeds by dividing the input list into two halves, recursively sorting each half, and then merging the sorted halves back together. The merging process involves comparing the first elements of each sorted sub-list and appending the smaller one to the output list. This process continues until one of the sub-lists is empty, at which point the remaining elements in the other sub-list are appended to the output list. Merge sort has the advantage of being a stable sorting algorithm, which means that elements with the same value retain their original order in the sorted list. Additionally, merge sort is well-suited to sorting linked lists, as it only requires changing pointers to merge the sub-lists, rather than copying elements as in an array-based implementation. However, merge sort does require additional memory for the merging process, and its recursive nature can lead to stack overflow on very large lists.

4)Quick Sort - Quick sort is a divide-and-conquer sorting algorithm that works by partitioning an input list into two sub-lists, sorting each sub-list independently, and then combining the sorted sub-lists back together. It is a highly efficient sorting algorithm, with an average time complexity of O(n log n) and a worst-case time complexity of O(n^2). The algorithm proceeds by selecting a pivot element from the input list and partitioning the list into two sub-lists, one containing elements smaller than the pivot and one containing elements larger than the pivot. The pivot element is then moved to its final position in the sorted list, and the two sub-lists are recursively sorted using the same process. Quick sort has the advantage of being an in-place sorting algorithm, meaning that it can sort the input list without requiring additional memory beyond the list itself. Additionally, quick sort is often faster than other comparison-based sorting algorithms for large data sets, due to its efficient partitioning scheme. However, quick sort can have poor performance on nearly sorted or already sorted lists, and its worst-case time complexity can be problematic for certain types of input. Various modifications to the basic algorithm, such as randomized pivot selection or hybridization with insertion sort, can mitigate these issues.

5)Selection Sort - Selection sort is a simple sorting algorithm that works by repeatedly finding the smallest element in an unsorted portion of the input list and swapping it with the first unsorted element. It has a worst-case time complexity of O(n^2), making it relatively inefficient for large data sets. The algorithm proceeds by iterating through the input list and selecting the smallest element in the unsorted portion of the list. This element is then swapped with the first unsorted element, effectively adding it to the sorted portion of the list. This process continues until the entire list is sorted. Selection sort has the advantage of being simple to implement and requiring only a small amount of additional memory for swapping elements. However, its time complexity makes it unsuitable for large data sets or real-time applications. Additionally, selection sort is not a stable sorting algorithm, meaning that the relative order of equal elements may change in the sorted list.






